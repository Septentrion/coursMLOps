{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression\n",
    "\n",
    "\n",
    "## Enoncé\n",
    "\n",
    "Le problème auquel nous sommes confrontés est l'estimation des prix des maisons à Boston. Le jeu de données à déjà été très bien étudié, particulier à cause de son homogénéité : toutes les *caractéristiques* sont numériques, il n'y a pas de données manquantes ou aberrantes et le nombre d'exemples est de 506, ce qui est peu mas pratique pour la pédagogie.\n",
    "\n",
    "Le jeu de données décrit les caractéristiques des maisons dans la périphérie de Boston, en évaluant leur prix en milliers de dollars. Le but est de parvenir à prédire le prix d'une maison en fonction de ses caractéristiques. En tant que tel, c'est typiquement un problème de **régression**.\n",
    "\n",
    "La performance du modèle sera estimée par la méthode l'[erreur quadratique moyenne](https://fr.wikipedia.org/wiki/Erreur_quadratique_moyenne) (MSE). L'objectif sera d'obtenir une erreur inférieure à 4.500 dollars sur le prix, soit un estimateur autour de 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Procédé\n",
    "\n",
    "\n",
    "### Examen du jeu de données\n",
    "\n",
    "Le jeu de données peut être téléchargé sur le site de l'UCI.\n",
    "\n",
    "**Source** : [Boston Housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/)\n",
    "\n",
    "Comme vous le verrez, il y a deux fichiers:\n",
    "\n",
    "* **housing.data** qui contient les données\n",
    "* **housing.names** qui contient la nomenclature\n",
    "\n",
    "Quelle forme ont les données ?\n",
    "\n",
    "Première étape : lire les données et les importer dans une structure de données numérique Python. Laquelle choisiriez-vous ?\n",
    "\n",
    "Seconde étape : représentez graphiquement des caractéristiques de manière à voir leur distributions.\n",
    "\n",
    "Troisème étape : séparer les caractéristiques des étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Construction du modèle\n",
    "\n",
    "Nous avons maintenant des `DataFrame` qui sont équivalents à des *tenseurs* de Tensorflow (ou l'inverse).\n",
    "\n",
    "La deuxième partie de l'exercice consiste à créer l'architecture du réseau qui sera chargé de donner une solution à notre problème.\n",
    "\n",
    "Nous avons besoin ici d'un modèle très simple qui comprend :\n",
    "\n",
    "* une couche d'entrée important les valeurs des exemples\n",
    "* une couche cachée (le problème n'est pas linéaire)\n",
    "* une couche de sortie\n",
    "\n",
    " Quatrième étape : définir les paramètres du réseau\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Normalisation\n",
    "\n",
    "Un point très important, lorsque l'on regarde les valeurs des différentes caractéristiques est la variabilité de leurs échelles, ce qui est normal puisqu'elles représentent des choses très différentes.\n",
    "\n",
    "Néanmoins, laisser les choses en l'état risque de pénaliser la qualité de l'apprentissage. D'une manière générale, on préférera avoir des valeurs normalisées et dans des intervalles relativement petits. C'et toujours une bonne pratique que de préparer les valeurs (numériques, naturellement) de cette manière.\n",
    "\n",
    "Sixième étape ; normaliser les valeurs\n",
    "\n",
    "Pour cela, on utilisera les ressources de [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
    "\n",
    "`StandardScaler` fait en sorte que toute la distribution soit centrée autour de zéro et réduite à l'écart-type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation\n",
    "\n",
    "On peut améliorer la phase d'apprentissage en définissant un estimateur pour la régression, via une classe de Keras.\n",
    "\n",
    "Ici, on aura recours à la classe [`KerasRegressor`](https://keras.io/scikit-learn-api/), qui est elle-même une spécialisation de la classe [`MLPRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) de Scikit-Learn\n",
    "\n",
    "`KerasRegressor` produit un modèle Keras qui pourra ensuite être utilisé lors de la phase d'entraînement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Pipeline\n",
    "\n",
    "En utilisant la classe `KerasRegressor`, nous pouvons maintenant optimiser le processus en demandant à enchaîner les différentes transformations.\n",
    "\n",
    "Nous allons devoir faire appel à une troisème bibliothèque (qui est à la base de tout) : `Scikit-Learn`.\n",
    "\n",
    "Scikit-Learn définit l'objet [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), qui permet faire ce que nous voulons :  chaîner entre elles différentes étapes du processus d'apprentissage et produire un estimateur, grâce auquel nous pourrons évaluer notre méthode.\n",
    "\n",
    "Cela nous assure aussi que l'on opère la normalisation durant la phase de validation, et qu'aucun échantillon du jeu de test ne sera mélangé avec les échantillons du jeu d'entraînement.\n",
    "\n",
    "Dans ce pipeline, on définira deux étapes :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Validation du modèle\n",
    "\n",
    "Une fois le modèle défini et compilé, nous pouvons lui fournir un jeu d'exemples et le réseau de neurones apprendra (plus ou moins bien) à corréler les caractéristiques, pour fournir des réponses à des cas qui ne se sont encore jamais présentés.\n",
    "\n",
    "Nous avons donc besoin d'un estimateur qui nous donne une idée de la qualité des résultats.\n",
    "\n",
    "Dans notre cas, nous choisissons l'[erreur quadratique moyenne](https://fr.wikipedia.org/wiki/Erreur_quadratique_moyenne).\n",
    "\n",
    "Cinquième étape : définir l'estimateur.\n",
    "\n",
    "Nous utiliserons la fonction [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score) qui nous permettra d'estimer la précision de l'apprentissage.\n",
    "\n",
    "Dans le cas le plus courant, l'ensemble d'apprentissage est scindé en “paquets” (folds) et pour ça nous utiliserons la classe [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exécution\n",
    "\n",
    "Une fois la phase de préparation terminée, il reste à exécuter l'entraînement ce qui se fait avec la méthode [`fit`](https://keras.io/models/sequential/#fit).\n",
    "\n",
    "`fit` opère sur un modèle muni d'un ensemble d'exemples et d'un ensemble d'étiquettes. En sortie, une valeur est déterminée pour chaque paramètre du réseau, c'est-à-dire que chaque connexion entre deux neurones aura un certain “poids”.\n",
    "\n",
    "Les principales options de la méthode `fit` font partie des hyperparamètres de l'apprentissage :\n",
    "\n",
    "* **epochs** : le nombre d'itérations\n",
    "* **batch_size** : la taille de chaque lot\n",
    "* **validation_split** : la taille du quota d'exemples utilisé à chaque itération pour valider l'apprentissage\n",
    "* **shuffle** : si l'on doit mélanger le jeu d'exemple avant chaque itération\n",
    "* **[`callbacks`](https://keras.io/callbacks/)** : une liste de fonctions à exécuter à certains moments de la phase d'apprentissage (fin de lot, fin d'itération, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Expérimentation\n",
    "\n",
    "Pour terminer, si on a des exemples différents non utilisés pour l'entraînement, nous pouvons les soumettre au réseau avec `predict`\n",
    "\n",
    "Et enfin mesurer la précision avec `accuracy_score`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Tuning\n",
    "\n",
    "Quel résultat obtenons-nous avec cette architecture ?\n",
    "\n",
    "Que se passe-t-il si vous réitérez plusieurs fois le cycle d'apprentissage ?\n",
    "\n",
    "Proposez des variations des hyperparamètres pour tenter d'améliorer la précision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
